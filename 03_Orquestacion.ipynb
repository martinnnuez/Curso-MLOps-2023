{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ciencia de Datos e Inteligencia Artificial para la industria del software**\n",
    "\n",
    "# *Curso MLOps*\n",
    "\n",
    "## **Edici贸n 2023**\n",
    "\n",
    "# 3. Orquestaci贸n\n",
    "\n",
    "## 3.1 Introducci贸n a la Orquestaci贸n de Flujos de Trabajo\n",
    "\n",
    "Orquestar un flujo de trabajo de ML puede ser bastante desafiante. Hay muchos puntos potenciales de interrupci贸n en el flujo, como indican las cruces rojas en la imagen:\n",
    "\n",
    "![Flujo T铆pico](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_3/ML_Ops_Zoomcamp_Module_3_files/figure-html/7985c817-ae3f-4b06-b7ad-c4a5be6efb81-2-5c4a30a6-4a39-4bd2-a17a-5533062dd67e.PNG)\n",
    "\n",
    "Afortunadamente, existen herramientas disponibles para solucionar estos problemas. Prefect proporciona un enfoque moderno, s贸lido y de f谩cil aplicaci贸n para la orquestaci贸n de flujos de trabajo, simplificando la gesti贸n de *pipelines* de datos complejas y permitiendo una ejecuci贸n eficiente y confiable, as铆 como el monitoreo y la visualizaci贸n de los flujos de trabajo.\n",
    "\n",
    "A continuaci贸n se muestra una captura de pantalla de la interfaz de usuario de Prefect que ilustra c贸mo se podr铆a orquestar un flujo t铆pico:\n",
    "\n",
    "![Interfaz de Usuario de Prefect](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_3/ML_Ops_Zoomcamp_Module_3_files/figure-html/7985c817-ae3f-4b06-b7ad-c4a5be6efb81-1-2d954052-efcf-49dc-9214-2453d17ea473.PNG)\n",
    "\n",
    "## 3.2 Introducci贸n a Prefect\n",
    "\n",
    "![Prefect](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_3/ML_Ops_Zoomcamp_Module_3_files/figure-html/cec5f8e8-85d2-4966-8e95-6a8af1e133a9-1-c372cec2-c169-43e5-bddc-af4cc2126188.PNG)\n",
    "\n",
    "Prefect es una herramienta de orquestaci贸n de flujos de trabajo que permite a los desarrolladores construir, observar y reaccionar ante *pipelines* de datos.\n",
    "\n",
    "Es la forma m谩s sencilla de transformar cualquier funci贸n Python en una unidad de trabajo que puede ser observada y orquestada. S贸lo tiene que incertar el c贸digo Python y colocar algunos decoradores.\n",
    "\n",
    "Prefect hace que sea f谩cil a帽adir reintentos autom谩ticos, almacenamiento en cach茅 y registro a tus funciones Python. S贸lo tienes que decorar tu c贸digo con decoradores de flujo y tareas y estar谩s volando. \n",
    "\n",
    "Prefect permite automatizar procesos, su objetivo principal es facilitar la gesti贸n y ejecuci贸n de flujos de trabajo complejos y distribuidos. \n",
    "\n",
    "#### Beneficios\n",
    "\n",
    "* Facilita la orquestaci贸n de flujos de trabajo complejos: Prefect permite **definir y gestionar flujos de trabajo** de manera program谩tica utilizando c贸digo Python. Esto hace que sea m谩s f谩cil representar y controlar flujos de trabajo complejos, donde las tareas deben ejecutarse en un orden espec铆fico o incluso en paralelo.\n",
    "\n",
    "* Control de flujo y manejo de errores: Con Prefect, puedes definir reglas de flujo y **manejo de errores de manera m谩s eficiente**. Puedes especificar qu茅 hacer **si una tarea falla, c贸mo reintentarla o c贸mo continuar con tareas alternativas en funci贸n de condiciones espec铆ficas**.\n",
    "\n",
    "* Programaci贸n distribuida: Prefect est谩 dise帽ado para ejecutar flujos de trabajo distribuidos, lo que significa que puedes **aprovechar recursos de c贸mputo distribuidos**, como cl煤steres de m谩quinas o plataformas de contenedores, para ejecutar tareas en paralelo y de manera escalable.\n",
    "\n",
    "* Monitorizaci贸n y seguimiento: Prefect proporciona herramientas para **monitorear y realizar un seguimiento detallado** de la ejecuci贸n de flujos de trabajo. Esto es valioso para el diagn贸stico de problemas y la mejora de la eficiencia de los flujos de trabajo.\n",
    "\n",
    "* Flexibilidad y extensibilidad: Puedes **integrar Prefect con otras herramientas y servicios**, lo que lo hace altamente flexible y adecuado para su uso en diversos entornos y situaciones. Tambi茅n es extensible, lo que significa que puedes personalizar y ampliar su funcionalidad seg煤n tus necesidades espec铆ficas.\n",
    "\n",
    "* Reproducibilidad y versionamiento: Prefect promueve las mejores pr谩cticas de **reproducibilidad y versionamiento** al permitirte definir flujos de trabajo como c贸digo, lo que facilita la reproducci贸n de experimentos y el seguimiento de cambios en tus flujos de trabajo a lo largo del tiempo.\n",
    "\n",
    "En el contexto de MLOps, Prefect se utiliza com煤nmente para orquestar flujos de trabajo relacionados con la preparaci贸n de datos, entrenamiento de modelos, evaluaci贸n de modelos, despliegue y monitorizaci贸n. Su capacidad para gestionar flujos de trabajo complejos y distribuidos es especialmente 煤til en proyectos de Machine Learning donde se requiere coordinar m煤ltiples etapas y recursos.\n",
    "\n",
    "#### Alternativas a Prefect\n",
    "\n",
    "* **Apache Airflow**: Es una de las herramientas m谩s conocidas para orquestaci贸n de flujos de trabajo. Airflow permite definir flujos de trabajo como DAGs (Grafos Ac铆clicos Dirigidos) y ofrece una amplia gama de conectores y operadores para integrarse con diversas tecnolog铆as y servicios.\n",
    "\n",
    "* **Luigi**: Desarrollado por Spotify, Luigi es otra herramienta de orquestaci贸n de flujos de trabajo. Al igual que Prefect, se utiliza para definir flujos de trabajo en Python y proporciona control de flujo y manejo de errores.\n",
    "\n",
    "* **Celery**: Aunque inicialmente se dise帽贸 para la cola de tareas y la ejecuci贸n paralela en aplicaciones web, Celery se puede utilizar para orquestaci贸n de flujos de trabajo cuando se combina con otras bibliotecas y herramientas.\n",
    "\n",
    "* **Kubeflow Pipelines**: Si est谩s trabajando en un entorno de Kubernetes, Kubeflow Pipelines es una excelente opci贸n. Est谩 dise帽ado espec铆ficamente para la orquestaci贸n de flujos de trabajo en Kubernetes y es ampliamente utilizado en el contexto de la automatizaci贸n de Machine Learning.\n",
    "\n",
    "* **AWS Step Functions**: Si est谩s en la nube de Amazon, AWS Step Functions es una opci贸n para orquestar flujos de trabajo en AWS. Puedes utilizarlo para coordinar servicios y recursos de AWS en tus flujos de trabajo.\n",
    "\n",
    "* **Microsoft Azure Data Factory**: Si trabajas en el entorno de Azure, Azure Data Factory es una herramienta que te permite crear, programar y orquestar flujos de trabajo de datos en la nube.\n",
    "\n",
    "* **Google Cloud Composer**: Si utilizas Google Cloud, Cloud Composer es una plataforma gestionada que se basa en Apache Airflow y est谩 dise帽ada para la orquestaci贸n de flujos de trabajo en Google Cloud.\n",
    "\n",
    "* **Rundeck**: Rundeck es una herramienta de orquestaci贸n de flujos de trabajo que se centra en la automatizaci贸n de tareas operativas y la gesti贸n de infraestructura.\n",
    "\n",
    "* **DAGsHub**: Una plataforma para gestionar flujos de trabajo de ML y Data Science que permite a los equipos colaborar en la orquestaci贸n y reproducci贸n de flujos de trabajo.\n",
    "\n",
    "* **Tekton**: Si est谩s construyendo flujos de trabajo de CI/CD en entornos de contenedores, Tekton es una opci贸n popular que se integra bien con Kubernetes.\n",
    "\n",
    "La elecci贸n de la herramienta depender谩 de tus necesidades espec铆ficas, los servicios y tecnolog铆as que utilices, y tus preferencias personales. Cada una de estas herramientas tiene sus propias caracter铆sticas y ventajas, por lo que es importante evaluarlas en funci贸n de tus requerimientos y restricciones particulares.\n",
    "\n",
    "### 3.2.1 驴Por qu茅 usar Prefect?\n",
    "\n",
    "![Razones para Usar Prefect](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_3/ML_Ops_Zoomcamp_Module_3_files/figure-html/24f13b5a-1120-4a68-b62f-ce0ef243ea04-1-6f845297-335f-49cb-867c-c22357338b3b.PNG)\n",
    "\n",
    "* **Facilidad de uso:**\n",
    "Prefect proporciona una interfaz de usuario amigable y una API basada en Python, lo que facilita la definici贸n y gesti贸n de flujos de trabajo. Le permite escribir flujos de trabajo como c贸digo, aprovechando su conocimiento e infraestructura Python existente.\n",
    "\n",
    "* **Flexibilidad:**\n",
    "Prefect ofrece un marco flexible y extensible para definir flujos de trabajo. Admite dependencias complejas y le permite manejar flujos de trabajo din谩micos impulsados por datos. Puede crear, actualizar y versionar f谩cilmente sus flujos de trabajo a medida que evolucionan sus necesidades.\n",
    "\n",
    "* **Tolerancia a fallos:**\n",
    "Prefect proporciona tolerancia a fallos incorporada y mecanismos de reintento. Maneja las fallas de manera elegante al volver a intentar autom谩ticamente las tareas fallidas y recuperarse de los errores. Puede configurar manejo de errores personalizados y notificaciones para garantizar que sus flujos de trabajo se ejecuten de manera confiable.\n",
    "\n",
    "* **Monitoreo y observabilidad:**\n",
    "Prefect ofrece caracter铆sticas completas de monitoreo y observabilidad. Proporciona un panel basado en web donde puede visualizar y seguir el estado de sus flujos de trabajo, inspeccionar detalles a nivel de tarea y monitorear m茅tricas de ejecuci贸n. Esto permite una f谩cil depuraci贸n, optimizaci贸n de rendimiento y soluci贸n de problemas.\n",
    "\n",
    "* **Escalabilidad:**\n",
    "Prefect est谩 dise帽ado para escalar horizontalmente, lo que le permite ejecutar flujos de trabajo en una infraestructura distribuida. Admite ejecuci贸n paralela y distribuida, lo que le permite ejecutar tareas de manera concurrente en m煤ltiples m谩quinas o contenedores. Esto lo hace adecuado para el procesamiento de datos a gran escala y flujos de trabajo complejos.\n",
    "\n",
    "* **Integraci贸n y extensibilidad:**\n",
    "Prefect se integra perfectamente con varias tecnolog铆as y servicios, como bases de datos, colas de mensajes, plataformas en la nube y m谩s. Proporciona una amplia variedad de bibliotecas de tareas y le permite extender su funcionalidad mediante definiciones de tareas personalizadas y ganchos. Esto le permite integrar Prefect en su conjunto de tecnolog铆as existente y aprovechar el poder de su ecosistema.\n",
    "\n",
    "* **Visibilidad y colaboraci贸n en flujos de trabajo:**\n",
    "Prefect promueve la colaboraci贸n y la visibilidad entre equipos. Ofrece caracter铆sticas como control de versiones, compartici贸n y edici贸n colaborativa de flujos de trabajo. Puede compartir y reutilizar f谩cilmente flujos de trabajo en proyectos, lo que permite una mejor colaboraci贸n y compartici贸n de conocimientos dentro de su organizaci贸n.\n",
    "\n",
    "![Flujos de Trabajo en Prefect](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_3/ML_Ops_Zoomcamp_Module_3_files/figure-html/48700e8c-7f1e-4f4b-8653-84f1c6f446b3-1-598ca6c1-9e24-4144-a8c0-a5eeb2f364a6.PNG)\n",
    "\n",
    "![Flujo Principal y Subflujo en Prefect](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_3/ML_Ops_Zoomcamp_Module_3_files/figure-html/bae279ae-826a-4ff0-8d76-6ef536bda595-1-65cf645f-3220-4309-a291-897449294d68.PNG)\n",
    "\n",
    "![Ejemplo de Flujo en Prefect](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_3/ML_Ops_Zoomcamp_Module_3_files/figure-html/e340c1ac-f033-4ebf-ac57-c3109c692f49-1-953ecfb5-7726-457f-bdff-270d188d7b83.PNG)\n",
    "\n",
    "En el ejemplo anterior, tenemos un flujo principal llamado \"Hello Flow\" que llama al subflujo \"Subflow\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo introductio 1\n",
    "\n",
    "### a. Clonar el repositorio de Prefect en GitHub\n",
    "\n",
    "Para clonar el repositorio de Prefect, navegue hasta el directorio donde desea clonar y ejecute el siguiente comando desde la l铆nea de comandos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'prefect-mlops-zoomcamp' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/discdiver/prefect-mlops-zoomcamp.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Configurar un entorno Conda\n",
    "\n",
    "Ahora, desde dentro de nuestro repo clonado, vamos a crear un entorno conda usando lo siguiente:\n",
    "\n",
    "```bash\n",
    "conda create -n prefect-ops python==3.9.12\n",
    "```\n",
    "y activamos el entorno usando :\n",
    "\n",
    "```bash\n",
    "conda activate prefect-ops\n",
    "```   \n",
    "Comprueba r谩pidamente que estamos utilizando la versi贸n correcta de Python :\n",
    "\n",
    "```bash\n",
    "python -V\n",
    "```\n",
    "A continuaci贸n, pip install las dependencias incluidas en el archivo requirements.txt :\n",
    "\n",
    "```bash\n",
    "conda install pip\n",
    "```\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "Para ver el contenido del .txt, escribe en la terminal\n",
    "\n",
    "```bash\n",
    "cat requirements.txt\n",
    "```\n",
    "\n",
    "### c. Iniciar un servidor Prefect\n",
    "\n",
    "Podemos iniciar un servidor Prefect desde la l铆nea de comandos:\n",
    "\n",
    "```bash\n",
    "prefect server start\n",
    "```\n",
    "\n",
    "Vamos a tomar la URL de la API y asegurarnos de que la aplicamos a nuestra configuraci贸n de Prefect para que estemos apuntando a la URL correcta de la API.\n",
    "\n",
    "Dentro de una nueva terminal, navega al mismo directorio que antes, activa el entorno conda y establece la URL de la API:\n",
    "\n",
    "```bash\n",
    "prefect config set PREFECT_API_URL=http://127.0.0.1:4200/api\n",
    "```\n",
    "\n",
    "Bien, ahora naveguemos a la carpeta 3.2 donde se encuentran los scripts que usaremos para ilustrar:\n",
    "\n",
    "```bash\n",
    "cat_facts.py\n",
    "```\n",
    "\n",
    "En caso de algun error: \n",
    "\n",
    "```bash\n",
    "pip install --upgrade pydantic prefect\n",
    "```\n",
    "\n",
    "A continuacion definiremos una "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">09:33:29.700 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'unselfish-quetzal'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'fetch'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "09:33:29.700 | \u001b[36mINFO\u001b[0m    | prefect.engine - Created flow run\u001b[35m 'unselfish-quetzal'\u001b[0m for flow\u001b[1;35m 'fetch'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">09:33:29.708 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'unselfish-quetzal'</span> - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:4200/flow-runs/flow-run/2450b3fc-9745-4f8e-a44a-1e7f8d37be41</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "09:33:29.708 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'unselfish-quetzal'\u001b[0m - View at \u001b[94mhttp://127.0.0.1:4200/flow-runs/flow-run/2450b3fc-9745-4f8e-a44a-1e7f8d37be41\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">09:33:29.834 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'unselfish-quetzal'</span> - Created task run 'fetch_cat_fact-0' for task 'fetch_cat_fact'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "09:33:29.834 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'unselfish-quetzal'\u001b[0m - Created task run 'fetch_cat_fact-0' for task 'fetch_cat_fact'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">09:33:29.836 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'unselfish-quetzal'</span> - Executing 'fetch_cat_fact-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "09:33:29.836 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'unselfish-quetzal'\u001b[0m - Executing 'fetch_cat_fact-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">09:33:33.550 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Task run 'fetch_cat_fact-0' - Encountered exception during execution:\n",
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\prefect\\engine.py\", line 1729, in orchestrate_task_run\n",
       "    result = await call.aresult()\n",
       "  File \"c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\prefect\\_internal\\concurrency\\calls.py\", line 291, in aresult\n",
       "    return await asyncio.wrap_future(self.future)\n",
       "  File \"c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\prefect\\_internal\\concurrency\\calls.py\", line 315, in _run_sync\n",
       "    result = self.fn(*self.args, **self.kwargs)\n",
       "  File \"C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_14544\\3890962043.py\", line 10, in fetch_cat_fact\n",
       "    raise Exception()\n",
       "Exception\n",
       "</pre>\n"
      ],
      "text/plain": [
       "09:33:33.550 | \u001b[38;5;160mERROR\u001b[0m   | Task run 'fetch_cat_fact-0' - Encountered exception during execution:\n",
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\prefect\\engine.py\", line 1729, in orchestrate_task_run\n",
       "    result = await call.aresult()\n",
       "  File \"c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\prefect\\_internal\\concurrency\\calls.py\", line 291, in aresult\n",
       "    return await asyncio.wrap_future(self.future)\n",
       "  File \"c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\prefect\\_internal\\concurrency\\calls.py\", line 315, in _run_sync\n",
       "    result = self.fn(*self.args, **self.kwargs)\n",
       "  File \"C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_14544\\3890962043.py\", line 10, in fetch_cat_fact\n",
       "    raise Exception()\n",
       "Exception\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">09:33:33.628 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'fetch_cat_fact-0' - Received non-final state 'AwaitingRetry' when proposing final state '<span style=\"color: #d70000; text-decoration-color: #d70000\">Failed</span>' and will attempt to run again...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "09:33:33.628 | \u001b[36mINFO\u001b[0m    | Task run 'fetch_cat_fact-0' - Received non-final state 'AwaitingRetry' when proposing final state '\u001b[38;5;160mFailed\u001b[0m' and will attempt to run again...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">09:33:34.591 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'fetch_cat_fact-0' - In the 1750s, Europeans introduced cats into the Americas to control pests.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "09:33:34.591 | \u001b[36mINFO\u001b[0m    | Task run 'fetch_cat_fact-0' - In the 1750s, Europeans introduced cats into the Americas to control pests.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">09:33:34.681 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'fetch_cat_fact-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "09:33:34.681 | \u001b[36mINFO\u001b[0m    | Task run 'fetch_cat_fact-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">09:33:34.756 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'unselfish-quetzal'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>('All states completed.')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "09:33:34.756 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'unselfish-quetzal'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m('All states completed.')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import httpx\n",
    "from prefect import flow, task\n",
    "\n",
    "\n",
    "@task(retries=4, retry_delay_seconds=0.1, log_prints=True) # decorator\n",
    "def fetch_cat_fact():\n",
    "    cat_fact = httpx.get(\"https://f3-vyx5c2hfpq-ue.a.run.app/\")\n",
    "    #An endpoint that is designed to fail sporadically\n",
    "    if cat_fact.status_code >= 400:\n",
    "        raise Exception()\n",
    "    print(cat_fact.text) # this will be logged\n",
    "\n",
    "\n",
    "@flow\n",
    "def fetch():\n",
    "    fetch_cat_fact()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este c贸digo est谩 utilizando la biblioteca Prefect para definir un flujo de trabajo simple que se encarga de realizar una solicitud HTTP a una p谩gina web y luego imprimir el contenido de la respuesta. A continuaci贸n la estructura y lo que est谩 haciendo este c贸digo:\n",
    "\n",
    "1. Importaciones:\n",
    "   ```python\n",
    "   import httpx\n",
    "   from prefect import flow, task\n",
    "   ```\n",
    "   - `httpx` es una biblioteca que se utiliza para realizar solicitudes HTTP.\n",
    "   - `prefect` es la biblioteca de orquestaci贸n de flujos de trabajo que se est谩 utilizando para definir el flujo de trabajo.\n",
    "\n",
    "2. Decorador `@task`:\n",
    "   ```python\n",
    "   @task(retries=4, retry_delay_seconds=0.1, log_prints=True)\n",
    "   ```\n",
    "   - Esto define una tarea llamada `fetch_cat_fact`. El decorador `@task` se utiliza para marcar esta funci贸n como una tarea que forma parte del flujo de trabajo Prefect.\n",
    "   - `retries=4` indica que esta tarea se volver谩 a intentar hasta 4 veces en caso de que falle.\n",
    "   - `retry_delay_seconds=0.1` establece un retraso de 0.1 segundos entre reintentos.\n",
    "   - `log_prints=True` permite que los mensajes de registro generados dentro de esta tarea se impriman en la salida est谩ndar.\n",
    "\n",
    "3. Funci贸n `fetch_cat_fact()`:\n",
    "   ```python\n",
    "   def fetch_cat_fact():\n",
    "       cat_fact = httpx.get(\"https://f3-vyx5c2hfpq-ue.a.run.app/\")\n",
    "       if cat_fact.status_code >= 400:\n",
    "           raise Exception()\n",
    "       print(cat_fact.text)\n",
    "   ```\n",
    "   - Esta funci贸n realiza una solicitud HTTP a la URL \"https://f3-vyx5c2hfpq-ue.a.run.app/\" utilizando `httpx.get()`.\n",
    "   - Luego, verifica si el c贸digo de estado de la respuesta es mayor o igual a 400, lo que generalmente indica un error HTTP. Si es as铆, se lanza una excepci贸n.\n",
    "   - Finalmente, imprime el contenido de la respuesta en la salida est谩ndar.\n",
    "\n",
    "4. Funci贸n `fetch()`:\n",
    "   ```python\n",
    "   @flow\n",
    "   def fetch():\n",
    "       fetch_cat_fact()\n",
    "   ```\n",
    "   - Esta funci贸n `fetch()` se marca como un flujo de trabajo Prefect utilizando el decorador `@flow`.\n",
    "   - En este caso, el flujo de trabajo es bastante simple y consiste en llamar a la tarea `fetch_cat_fact()`.\n",
    "\n",
    "5. Ejecuci贸n del flujo de trabajo:\n",
    "   ```python\n",
    "   if __name__ == \"__main__\":\n",
    "       fetch()\n",
    "   ```\n",
    "   - Esta secci贸n verifica si el script se est谩 ejecutando como el programa principal (`__name__ == \"__main__\"`).\n",
    "   - Si es as铆, se inicia la ejecuci贸n del flujo de trabajo `fetch()`.\n",
    "\n",
    "En resumen, este c贸digo define un flujo de trabajo Prefect que realiza una solicitud HTTP a una URL y maneja posibles errores HTTP. La respuesta de la solicitud se imprime en la salida est谩ndar. La estructura es t铆pica de c贸mo se definen y ejecutan flujos de trabajo utilizando la biblioteca Prefect en Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funci贸n que llama a la API ha sido decorada con un decorador de tareas que ha sido configurado con los argumentos retries, retry_delay_seconds, y log_prints.\n",
    "\n",
    "Podemos ejecutar el flujo desde la l铆nea de comandos utilizando:\n",
    "\n",
    "```bash\n",
    "python cat_facts.py\n",
    "```\n",
    "\n",
    "y seguir la ejecuci贸n en directo desde la UPI de Prefect.\n",
    "\n",
    "Como podemos ver, el flujo fall贸 un par de veces, pero el argumento de reintentos incluido en el decorador funcion贸. Y ya tenemos nuestro hecho del gato registrado:\n",
    "\n",
    "\"A diferencia de los perros, los gatos no han sufrido grandes cambios durante su proceso de domesticaci贸n\".\n",
    "\n",
    "**Ejecutemos ahora el otro script:**\n",
    "\n",
    "```bash\n",
    "python cat_dog_facts.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:59:23.057 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'amorphous-mink'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'animal-facts'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:59:23.057 | \u001b[36mINFO\u001b[0m    | prefect.engine - Created flow run\u001b[35m 'amorphous-mink'\u001b[0m for flow\u001b[1;35m 'animal-facts'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:59:23.060 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'amorphous-mink'</span> - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:4200/flow-runs/flow-run/fedff82c-8cba-4425-9a06-37bc0c37c8aa</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:59:23.060 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'amorphous-mink'\u001b[0m - View at \u001b[94mhttp://127.0.0.1:4200/flow-runs/flow-run/fedff82c-8cba-4425-9a06-37bc0c37c8aa\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:59:23.303 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'amorphous-mink'</span> - Created subflow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'amiable-harrier'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'fetch-cat-fact'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:59:23.303 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'amorphous-mink'\u001b[0m - Created subflow run\u001b[35m 'amiable-harrier'\u001b[0m for flow\u001b[1;35m 'fetch-cat-fact'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:59:23.305 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'amiable-harrier'</span> - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:4200/flow-runs/flow-run/b1e85791-609b-42ca-b5d0-a6c87d0420ff</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:59:23.305 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'amiable-harrier'\u001b[0m - View at \u001b[94mhttp://127.0.0.1:4200/flow-runs/flow-run/b1e85791-609b-42ca-b5d0-a6c87d0420ff\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:59:24.633 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'amiable-harrier'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:59:24.633 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'amiable-harrier'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:59:24.771 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'amorphous-mink'</span> - Created subflow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'unyielding-chinchilla'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'fetch-dog-fact'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:59:24.771 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'amorphous-mink'\u001b[0m - Created subflow run\u001b[35m 'unyielding-chinchilla'\u001b[0m for flow\u001b[1;35m 'fetch-dog-fact'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:59:24.775 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'unyielding-chinchilla'</span> - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:4200/flow-runs/flow-run/132334d3-dc0e-4379-95fa-ce19db9fc363</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:59:24.775 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'unyielding-chinchilla'\u001b[0m - View at \u001b[94mhttp://127.0.0.1:4200/flow-runs/flow-run/132334d3-dc0e-4379-95fa-ce19db9fc363\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:59:26.442 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'unyielding-chinchilla'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:59:26.442 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'unyielding-chinchilla'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:59:26.444 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'amorphous-mink'</span> - : Today there are about 100 distinct breeds of the domestic cat.\n",
       ": While not the best when it comes to sight, dogs have a keen sense of hearing, and can hear sounds at 4 times the distance of humans.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:59:26.444 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'amorphous-mink'\u001b[0m - : Today there are about 100 distinct breeds of the domestic cat.\n",
       ": While not the best when it comes to sight, dogs have a keen sense of hearing, and can hear sounds at 4 times the distance of humans.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:59:26.492 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'amorphous-mink'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>('All states completed.')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:59:26.492 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'amorphous-mink'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m('All states completed.')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import httpx\n",
    "from prefect import flow\n",
    "\n",
    "@flow\n",
    "def fetch_cat_fact():\n",
    "    '''A flow that gets a cat fact'''\n",
    "    return httpx.get(\"https://catfact.ninja/fact?max_length=140\").json()[\"fact\"]\n",
    "\n",
    "@flow\n",
    "def fetch_dog_fact():\n",
    "    '''A flow that gets a dog fact'''\n",
    "    return httpx.get(\n",
    "        \"https://dogapi.dog/api/v2/facts\",\n",
    "        headers={\"accept\": \"application/json\"},\n",
    "    ).json()[\"data\"][0][\"attributes\"][\"body\"] # index into the JSON file to retrieve the \"body\" - see below for example of JSON format\n",
    "\n",
    "@flow(log_prints=True)\n",
    "def animal_facts():\n",
    "    cat_fact = fetch_cat_fact()\n",
    "    dog_fact = fetch_dog_fact()\n",
    "    print(f\": {cat_fact} \\n: {dog_fact}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    animal_facts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este script utiliza Subflows. El flujo principal `animal_facts` llama a `fetch_cat_fact` y luego a `fetch_dog_fact`. Ten en cuenta que debido a `log_prints=True`, la salida de los flujos se imprime y registra.\n",
    "\n",
    ": En la versi贸n original italiana de La Cenicienta, la figura ben茅vola del hada madrina era un gato.\n",
    "\n",
    ": La canci贸n de The Beatles \"A Day in the Life\" tiene un silbido extra agudo, audible solo para los perros. Fue grabado por Paul McCartney para el disfrute de su perro pastor de Shetland.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Flujo de Trabajo de Prefect\n",
    "\n",
    "### 3.3.1 Predicci贸n ride duration trip (Notebook del M贸dulo 2)\n",
    "\n",
    "En la primera clase construimos un modelo simple de predicci贸n de duraci贸n de viaje en taxi en la ciudad de Nueva York. El c贸digo fue compilado deliberadamente en un cuaderno Jupyter, el cual involucra el proceso de pensamiento y los pasos generales involucrados en la exploraci贸n y preprocesamiento de datos crudos para el entrenamiento de aprendizaje autom谩tico. Si bien un cuaderno Jupyter es adecuado para la experimentaci贸n interna, cuando se trata de producci贸n/despliegue, quiz谩s necesitamos algo m谩s robusto y escalable.\n",
    "\n",
    "Cuando el c贸digo est谩 disperso en un cuaderno Jupyter, las cosas pueden volverse r谩pidamente desordenadas, especialmente cuando comienzas a iterar sobre diferentes modelos y par谩metros. Puede haber una sensaci贸n de que est谩s perdiendo el control sobre tu experimento. Un primer paso hacia la mejora es unificar todo en un solo script de Python.\n",
    "\n",
    "### 3.3.2 Predicci贸n de la duraci贸n del viaje en un script de Python\n",
    "\n",
    "Un primer paso hacia la mejora es unificar todo en un solo script de Python:\n",
    "\n",
    "`orchestrate_pre_prefect.py`\n",
    "\n",
    "Este script unifica todos los procedimientos necesarios para entrenar el modelo de aprendizaje automatico desarrollado preivamente.\n",
    "\n",
    "   ```python\n",
    "import pathlib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import mlflow\n",
    "import xgboost as xgb\n",
    "from prefect import flow, task\n",
    "\n",
    "\n",
    "def read_data(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"Read data into DataFrame\"\"\"\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "    df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "\n",
    "    df[\"duration\"] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = [\"PULocationID\", \"DOLocationID\"]\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_features(\n",
    "    df_train: pd.DataFrame, df_val: pd.DataFrame\n",
    ") -> tuple(\n",
    "    [\n",
    "        scipy.sparse._csr.csr_matrix,\n",
    "        scipy.sparse._csr.csr_matrix,\n",
    "        np.ndarray,\n",
    "        np.ndarray,\n",
    "        sklearn.feature_extraction.DictVectorizer,\n",
    "    ]\n",
    "):\n",
    "    \"\"\"Add features to the model\"\"\"\n",
    "    df_train[\"PU_DO\"] = df_train[\"PULocationID\"] + \"_\" + df_train[\"DOLocationID\"]\n",
    "    df_val[\"PU_DO\"] = df_val[\"PULocationID\"] + \"_\" + df_val[\"DOLocationID\"]\n",
    "\n",
    "    categorical = [\"PU_DO\"]  #'PULocationID', 'DOLocationID']\n",
    "    numerical = [\"trip_distance\"]\n",
    "\n",
    "    dv = DictVectorizer()\n",
    "\n",
    "    train_dicts = df_train[categorical + numerical].to_dict(orient=\"records\")\n",
    "    X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "    val_dicts = df_val[categorical + numerical].to_dict(orient=\"records\")\n",
    "    X_val = dv.transform(val_dicts)\n",
    "\n",
    "    y_train = df_train[\"duration\"].values\n",
    "    y_val = df_val[\"duration\"].values\n",
    "    return X_train, X_val, y_train, y_val, dv\n",
    "\n",
    "\n",
    "def train_best_model(\n",
    "    X_train: scipy.sparse._csr.csr_matrix,\n",
    "    X_val: scipy.sparse._csr.csr_matrix,\n",
    "    y_train: np.ndarray,\n",
    "    y_val: np.ndarray,\n",
    "    dv: sklearn.feature_extraction.DictVectorizer,\n",
    ") -> None:\n",
    "    \"\"\"train a model with best hyperparams and write everything out\"\"\"\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        train = xgb.DMatrix(X_train, label=y_train)\n",
    "        valid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "        best_params = {\n",
    "        'learning_rate': 0.4434065752589766,\n",
    "        'max_depth': 81,\n",
    "        'min_child_weight': 10.423237853746643,\n",
    "        'objective': 'reg:linear',\n",
    "        'reg_alpha': 0.2630756846813668,\n",
    "        'reg_lambda': 0.1220536223877784,\n",
    "        'seed': 42    \n",
    "        }\n",
    "\n",
    "        mlflow.log_params(best_params)\n",
    "\n",
    "        booster = xgb.train(\n",
    "            params=best_params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=3,\n",
    "            evals=[(valid, \"validation\")],\n",
    "            early_stopping_rounds=3,\n",
    "        )\n",
    "\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        pathlib.Path(\"models\").mkdir(exist_ok=True)\n",
    "        with open(\"models/preprocessor.b\", \"wb\") as f_out:\n",
    "            pickle.dump(dv, f_out)\n",
    "        mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "        mlflow.xgboost.log_model(booster, artifact_path=\"models_mlflow\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def main_flow(\n",
    "    train_path: str = \"./data/yellow_tripdata_2022-01.parquet\",\n",
    "    val_path: str = \"./data/yellow_tripdata_2022-02.parquet\",\n",
    ") -> None:\n",
    "    \"\"\"The main training pipeline\"\"\"\n",
    "\n",
    "    # MLflow settings\n",
    "    mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "    mlflow.set_experiment(\"nyc-taxi-experiment\")\n",
    "\n",
    "    # Load\n",
    "    df_train = read_data(train_path)\n",
    "    df_val = read_data(val_path)\n",
    "\n",
    "    # Transform\n",
    "    X_train, X_val, y_train, y_val, dv = add_features(df_train, df_val)\n",
    "\n",
    "    # Train\n",
    "    train_best_model(X_train, X_val, y_train, y_val, dv)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_flow()\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, navega al directorio (3.3) donde se encuentra `orchestrate_pre_prefect.py` y ejecuta desde la l铆nea de comandos:\n",
    "\n",
    "```bash\n",
    "python orchestrate_pre_prefect.py\n",
    "```\n",
    "\n",
    "* *Si hay algun error borrar la DB de Mlflow* (alembic)\n",
    "\n",
    "Podemos agregar m谩s refinamiento utilizando Prefect. Veamos esto en acci贸n.\n",
    "\n",
    "### 3.3.2 Aprovechando Prefect para mejorar el script (**orquestaci贸n**)\n",
    "\n",
    "Podemos continuar construyendo sobre el script de Python agregando tareas y decoradores de flujo:\n",
    "\n",
    "`orchestrate.py`\n",
    "\n",
    "Explicaci贸n codigo: \n",
    "\n",
    "```python\n",
    "import pathlib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import mlflow\n",
    "import xgboost as xgb\n",
    "from prefect import flow, task\n",
    "```\n",
    "\n",
    "En esta parte, se realizan importaciones de bibliotecas y m贸dulos necesarios para el flujo de trabajo. `prefect` se importa junto con otras bibliotecas de Python que se utilizar谩n m谩s adelante.\n",
    "\n",
    "```python\n",
    "@task(retries=3, retry_delay_seconds=2)\n",
    "def read_data(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"Read data into DataFrame\"\"\"\n",
    "    # ... (Carga y procesamiento de datos) ...\n",
    "    return df\n",
    "```\n",
    "\n",
    "- `@task` es un decorador que marca la funci贸n `read_data` como una tarea Prefect. Esta tarea carga un archivo de datos en formato parquet, realiza varias transformaciones en el DataFrame y devuelve el DataFrame procesado. Tambi茅n tiene configuraci贸n de reintentos en caso de fallo.\n",
    "\n",
    "```python\n",
    "@task\n",
    "def add_features(\n",
    "    df_train: pd.DataFrame, df_val: pd.DataFrame\n",
    ") -> tuple(\n",
    "    [\n",
    "        scipy.sparse._csr.csr_matrix,\n",
    "        scipy.sparse._csr.csr_matrix,\n",
    "        np.ndarray,\n",
    "        np.ndarray,\n",
    "        sklearn.feature_extraction.DictVectorizer,\n",
    "    ]\n",
    "):\n",
    "    \"\"\"Add features to the model\"\"\"\n",
    "    # ... (Agrega caracter铆sticas al conjunto de datos y realiza la vectorizaci贸n de caracter铆sticas) ...\n",
    "    return X_train, X_val, y_train, y_val, dv\n",
    "```\n",
    "\n",
    "- La funci贸n `add_features` es otra tarea Prefect que agrega caracter铆sticas al conjunto de datos y utiliza `DictVectorizer` para transformar caracter铆sticas categ贸ricas en una representaci贸n num茅rica. Devuelve varias matrices y objetos relacionados.\n",
    "\n",
    "```python\n",
    "@task(log_prints=True)\n",
    "def train_best_model(\n",
    "    X_train: scipy.sparse._csr.csr_matrix,\n",
    "    X_val: scipy.sparse._csr.csr_matrix,\n",
    "    y_train: np.ndarray,\n",
    "    y_val: np.ndarray,\n",
    "    dv: sklearn.feature_extraction.DictVectorizer,\n",
    ") -> None:\n",
    "    \"\"\"train a model with best hyperparams and write everything out\"\"\"\n",
    "    # ... (Entrenamiento de un modelo XGBoost, registro de par谩metros y m茅tricas con MLflow) ...\n",
    "    return None\n",
    "```\n",
    "\n",
    "- `train_best_model` es la tercera tarea Prefect en el flujo de trabajo. Entrena un modelo XGBoost con hiperpar谩metros espec铆ficos, registra los par谩metros y m茅tricas de rendimiento con MLflow, y guarda el modelo entrenado y otros artefactos en el sistema de archivos.\n",
    "\n",
    "```python\n",
    "@flow\n",
    "def main_flow(\n",
    "    train_path: str = \"./data/yellow_tripdata_2022-01.parquet\",\n",
    "    val_path: str = \"./data/yellow_tripdata_2022-02.parquet\",\n",
    ") -> None:\n",
    "    \"\"\"The main training pipeline\"\"\"\n",
    "    # ... (Configuraci贸n de MLflow, carga de datos, transformaci贸n de caracter铆sticas y entrenamiento de modelo) ...\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_flow()\n",
    "```\n",
    "\n",
    "- `main_flow` es la funci贸n que define el flujo de trabajo principal. Configura MLflow, carga datos de archivos parquet, realiza transformaciones de caracter铆sticas y entrena un modelo utilizando las tareas Prefect definidas anteriormente.\n",
    "\n",
    "- La secci贸n final verifica si el script se est谩 ejecutando como el programa principal (`if __name__ == \"__main__\"`) y, si es as铆, ejecuta el flujo de trabajo principal llamando a `main_flow()`.\n",
    "\n",
    "En resumen, este c贸digo utiliza Prefect para definir un flujo de trabajo que incluye tareas para cargar y procesar datos, transformar caracter铆sticas y entrenar un modelo de aprendizaje autom谩tico. Prefect permite organizar y ejecutar estas tareas de manera eficiente, facilitando la automatizaci贸n y el seguimiento de todo el proceso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero navegue hasta el directorio donde se encuentra orchestrate.py y ejecute desde la l铆nea de comandos :\n",
    "\n",
    "```bash\n",
    "python orchestrate.py\n",
    "```\n",
    "Y podemos visualizar la ejecuci贸n usando el Prefect UI.\n",
    "\n",
    "* Si llegase a ocurrir un error borrar **mlflow.db**\n",
    "\n",
    "Una vez ejecutado explorar la corrida en la API. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
