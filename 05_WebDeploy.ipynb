{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ciencia de Datos e Inteligencia Artificial para la industria del software**\n",
    "\n",
    "# *Curso MLOps*\n",
    "\n",
    "## **Edici贸n 2023**\n",
    "\n",
    "# 5. Web depoyment\n",
    "\n",
    "*Despliegue de modelo en la web*\n",
    "\n",
    "Por decirlo de alguna forma, si no puedes sacar tus modelos de aprendizaje autom谩tico de un *notebook*, probablemente no se utilizar谩n. Este art铆culo deber铆a ayudarte a crear un **despliegue de tu modelo lo m谩s r谩pido posible, para que puedas implementar tus modelos rapidamente**. Se trata de una habilidad importante, ya que significa que **no depender谩s indispensablemente de un ingeniero/desarrollador de software para poder poner un modelo en producci贸n.** \n",
    "\n",
    "Para ello utilizaremos ***Hugging Face***. \n",
    "\n",
    "### 驴Qu茅 es Hugging Face ?\n",
    "\n",
    "- Una [comunidad colaborativa](https://huggingface.co/) especialmente enfocada en modelos de lenguaje y otros recursos de Inteligencia Artificial (IA).\n",
    "- Ofrece repositorios para disponibilizar [modelos](https://huggingface.co/models), [datasets](https://huggingface.co/datasets) y [demos](https://huggingface.co/spaces).\n",
    "- Adem谩s, ofrece varias librer铆as orientadas a la IA, particularmente al Aprendizaje Profundo (*Deep Learning*), entre las que destacan:\n",
    "    - [`transformers`](https://huggingface.co/docs/transformers): La que veremos en esta charla, para todo lo relacionado a Procesamiento del Lenguaje Natural (PLN) con grandes modelos de lenguaje (*Large Language Models*, LLMs).\n",
    "    - [`datasets`](https://huggingface.co/docs/datasets): Una librer铆a con funcionalidades para el tratamiento de los conjuntos de datos a utilizar para entrenar o ajustar los LLMs.\n",
    "    - [`tokenizers`](https://huggingface.co/docs/tokenizers): Una librer铆a para el proceso de \"tokenizaci贸n\", i.e. la divisi贸n de texto de manera discreta en palabras o subpalabras.\n",
    "- Hugging Face no s贸lo ofrece soluciones para PLN, sino tambi茅n para im谩genes, con librer铆as como [`diffusers`](https://huggingface.co/docs/diffusers), para la generaci贸n de im谩genes:\n",
    "    - Lectura recomendada: [The Illustrated Stable Diffusion](http://jalammar.github.io/illustrated-stable-diffusion/)\n",
    "\n",
    "Huggin Face es una empresa que busca desarrollar herramientas de c贸digo abierto para el dise帽o, entrenamiento y puesta en producci贸n de modelos de inteligencia artificial. Creada en 2016, empez贸 a ganar popularidad gracias a su librer铆a transformers, la cual permite crear y entrenar redes neuronales con la arquitectura *Transformer* de manera sencilla e independiente del framework agn贸stica, pudiendo usar en el backend tanto Pytorch como Tensorflo o JAX. Hoy en d铆a, sin embargo, ofrece muchas otras funcionalidades tales como *Datasets*, Modelos pre-entrenados, herramientas para el entrenamiento y puesta en producci贸n de modelos a escala, etc. Recientemente incluso han inclu铆do en su cat谩logo la librer铆a timm, para la generaci贸n de im谩genes al estilo *DALL-E* o *Stable Diffusion*, indicando que Hugging Face est谩 creciendo como comunidad, yendo m谩s all谩 de los *Transfromers* y sus aplicaciones en tareas de lenguaje hacia otros campos como el de la visi贸n artificial o el aprendizaje por refuerzo. \n",
    "\n",
    "## 驴C贸mo empezar con Hugging Face ?\n",
    "\n",
    "- Primero se [crea una cuenta en la p谩gina](https://huggingface.co/join).\n",
    "- Luego podemos [crear modelos](https://huggingface.co/new) a trav茅s del men煤 que se despliega de nuestro avatar.\n",
    "\n",
    "Este es el esquema que seguiremos:\n",
    "\n",
    "**1.** Crear una cuenta de Hugging Face \n",
    "* [crea una cuenta en la p谩gina](https://huggingface.co/join).\n",
    "\n",
    "**2.** Crear un *Space* en Hugging Face y configurarlo\n",
    "* Los Spaces son repositorios Git que alojan c贸digo de aplicaci贸n para demos de Machine Learning.\n",
    "\n",
    "a- Seleccione el SDK de Space: **Gradio**.\n",
    "b- Space hardware: **Free**.\n",
    "c- Public.\n",
    "d- Create space.\n",
    "\n",
    "\n",
    "**Archivos necesarios:**  \n",
    "\n",
    "* .gitattributes (Creado automaticamente)\n",
    "* README.md (Creado automaticamente)\n",
    "* app.py (app propiamente dicha que realizara la predicci贸n)\n",
    "* model.pkl (modelo previamente entrenado)\n",
    "* requirements.txt (requirements del environment con el cual entrenamos nuestro modelo)\n",
    "\n",
    "\n",
    "**3.** Cargamos el modelo y el preprocesador previamente entrenados:\n",
    "\n",
    "* lin_reg.bin\n",
    "* preprocessor.b\n",
    "\n",
    "**4.** Crear y subir el archivo app.py que realizara el preprocesamiento y las predicciones:\n",
    "\n",
    "### **app.py** \n",
    "\n",
    "```bash\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import pathlib\n",
    "#plt = platform.system()\n",
    "#if plt == 'Linux': pathlib.WindowsPath = pathlib.PosixPath\n",
    "\n",
    "with open('lin_reg.bin', 'rb') as f_in:\n",
    "    (dv, model) = pickle.load(f_in)\n",
    "\n",
    "def prepare_features(ride):\n",
    "    features = {}\n",
    "    features['PU_DO'] = '%s_%s' % (ride['PULocationID'], ride['DOLocationID'])\n",
    "    features['trip_distance'] = ride['trip_distance']\n",
    "    return features\n",
    "    \n",
    "def predict(features):\n",
    "    X = dv.transform(features)\n",
    "    preds = model.predict(X)\n",
    "    return float(preds[0])\n",
    "\n",
    "def main(PULocationID,DOLocationID,trip_distance):\n",
    "    \"\"\"request input, preprocess it and make prediction\"\"\"\n",
    "    input_data = {\n",
    "    \"PULocationID\": PULocationID,\n",
    "    \"DOLocationID\": DOLocationID,\n",
    "    \"trip_distance\": trip_distance\n",
    "    }\n",
    "    features = prepare_features(input_data)\n",
    "    pred = predict(features)\n",
    "\n",
    "    result = {\n",
    "        'duration': pred\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "#create input and output objects\n",
    "#input\n",
    "input1 = gr.inputs.Number()\n",
    "input2 = gr.inputs.Number()\n",
    "input3 = gr.inputs.Number()\n",
    "\n",
    "#output object\n",
    "output = gr.outputs.Textbox() \n",
    "\n",
    "intf = gr.Interface(title = \"New York taxi duration prediction\",\n",
    "                    description = \"The objective of this project is to predict the duration of a taxi trip in the city of New York.\",\n",
    "                    fn=main, \n",
    "                    inputs=[input1,input2,input3], \n",
    "                    outputs=[output], \n",
    "                    live=True,\n",
    "                    enable_queue=True\n",
    "                    )\n",
    "intf.launch()\n",
    "```\n",
    "\n",
    "**5.** Crear y subir el archivo requirements.txt:\n",
    "\n",
    "### requirements.txt\n",
    "\n",
    "```bash\n",
    "pandas==2.1.1\n",
    "scikit-learn==1.3.1\n",
    "```\n",
    "\n",
    "**6.** Entrar a la ventana de App, esperar que se construya y realizar predicciones!!!.\n",
    "\n",
    "[Mi app](https://huggingface.co/spaces/martinnnuez/New_york_taxi_duration_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicaci贸n cada chunk del c贸gido app.py:\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import pathlib\n",
    "```\n",
    "* Importaci贸n de bibliotecas: En esta secci贸n, se importan las bibliotecas necesarias. Estas bibliotecas incluyen \"pickle\" para cargar el modelo previamente entrenado, \"pandas\" y \"numpy\" para el procesamiento de datos, y \"gradio\" para crear una interfaz de usuario para la aplicaci贸n.\n",
    "\n",
    "```python\n",
    "with open('lin_reg.bin', 'rb') as f_in:\n",
    "    (dv, model) = pickle.load(f_in)\n",
    "```\n",
    "* Carga del modelo: En esta secci贸n, se abre el archivo \"lin_reg.bin\", que contiene un modelo previamente entrenado, se carga en las variables \"dv\" (vectorizador de caracter铆sticas) y \"model\" (modelo de regresi贸n lineal).\n",
    "\n",
    "```python\n",
    "def prepare_features(ride):\n",
    "    features = {}\n",
    "    features['PU_DO'] = '%s_%s' % (ride['PULocationID'], ride['DOLocationID'])\n",
    "    features['trip_distance'] = ride['trip_distance']\n",
    "    return features\n",
    "```\n",
    "* Funci贸n \"prepare_features\": Esta funci贸n toma un objeto \"ride\" como entrada y prepara las caracter铆sticas necesarias para hacer una predicci贸n. Crea un diccionario \"features\" que contiene las ubicaciones de recogida y entrega concatenadas en \"PU_DO\" y la distancia del viaje en \"trip_distance\". Luego, devuelve este diccionario de caracter铆sticas.\n",
    "\n",
    "```python\n",
    "def predict(features):\n",
    "    X = dv.transform(features)\n",
    "    preds = model.predict(X)\n",
    "    return float(preds[0])\n",
    "```\n",
    "* Funci贸n \"predict\": Esta funci贸n toma un diccionario de caracter铆sticas \"features\" como entrada. Utiliza el vectorizador de caracter铆sticas \"dv\" para transformar las caracter铆sticas en un formato adecuado y, a continuaci贸n, hace una predicci贸n utilizando el modelo previamente cargado. Devuelve la duraci贸n del viaje predicha como un n煤mero flotante.\n",
    "\n",
    "```python\n",
    "def main(PULocationID, DOLocationID, trip_distance):\n",
    "    \"\"\"request input, preprocess it and make a prediction\"\"\"\n",
    "    input_data = {\n",
    "        \"PULocationID\": PULocationID,\n",
    "        \"DOLocationID\": DOLocationID,\n",
    "        \"trip_distance\": trip_distance\n",
    "    }\n",
    "    features = prepare_features(input_data)\n",
    "    pred = predict(features)\n",
    "\n",
    "    result = {\n",
    "        'duration': pred\n",
    "    }\n",
    "\n",
    "    return result\n",
    "```\n",
    "* Funci贸n \"main\": Esta funci贸n toma como entrada las ubicaciones de recogida (\"PULocationID\"), las ubicaciones de entrega (\"DOLocationID\") y la distancia del viaje (\"trip_distance\"). Luego, crea un diccionario \"input_data\" con estas entradas y llama a las funciones \"prepare_features\" y \"predict\" para obtener una predicci贸n de la duraci贸n del viaje. La funci贸n devuelve el resultado en un diccionario con la clave \"duration\".\n",
    "\n",
    "```python\n",
    "# Creaci贸n de objetos de entrada y salida\n",
    "# Entradas\n",
    "input1 = gr.inputs.Number(label=\"PULocationID\")\n",
    "input2 = gr.inputs.Number(label=\"DOLocationID\")\n",
    "input3 = gr.inputs.Number(label=\"trip_distance\")\n",
    "\n",
    "# Salida\n",
    "output = gr.outputs.Textbox(label=\"Duraci贸n estimada del viaje\")\n",
    "\n",
    "intf = gr.Interface(\n",
    "    title=\"Predicci贸n de duraci贸n de viaje en taxis de Nueva York\",\n",
    "    description=\"El objetivo de este proyecto es predecir la duraci贸n de un viaje en taxi en la ciudad de Nueva York.\",\n",
    "    fn=main,\n",
    "    inputs=[input1, input2, input3],\n",
    "    outputs=[output],\n",
    "    live=True,\n",
    "    enable_queue=True\n",
    ")\n",
    "intf.launch()\n",
    "```\n",
    "\n",
    "* Interfaz Gradio: En esta secci贸n se crea la interfaz de usuario utilizando la biblioteca Gradio. Se definen objetos de entrada y salida para la interfaz, que incluyen etiquetas y tipos de datos. Luego, se crea la interfaz en s铆, especificando el t铆tulo, descripci贸n, funci贸n \"main\" que realizar谩 la predicci贸n y los objetos de entrada y salida. La interfaz se inicia y se pone en marcha."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
