{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ciencia de Datos e Inteligencia Artificial para la industria del software**\n",
    "\n",
    "# *Curso MLOps*\n",
    "\n",
    "## **Edici칩n 2023**\n",
    "\n",
    "# 5. Web depoyment\n",
    "\n",
    "*Despliegue de modelo en la web*\n",
    "\n",
    "Por decirlo de alguna forma, si no puedes sacar tus modelos de aprendizaje autom치tico de un *notebook*, probablemente no se utilizar치n. Este art칤culo deber칤a ayudarte a crear un despliegue de tu modelo lo m치s r치pido posible, para que puedas implementar tus modelos rapidamente. Se trata de una habilidad importante, ya que significa que no depender치s indispensablemente de un ingeniero/desarrollador de software para poder poner un modelo en producci칩n. \n",
    "\n",
    "Para ello utilizaremos *Hugging Face*. \n",
    "\n",
    "### 쯈u칠 es Hugging Face 游뱅?\n",
    "\n",
    "- Una [comunidad colaborativa](https://huggingface.co/) especialmente enfocada en modelos de lenguaje y otros recursos de Inteligencia Artificial (IA).\n",
    "- Ofrece repositorios para disponibilizar [modelos](https://huggingface.co/models), [datasets](https://huggingface.co/datasets) y [demos](https://huggingface.co/spaces).\n",
    "- Adem치s, ofrece varias librer칤as orientadas a la IA, particularmente al Aprendizaje Profundo (*Deep Learning*), entre las que destacan:\n",
    "    - [`transformers`](https://huggingface.co/docs/transformers): La que veremos en esta charla, para todo lo relacionado a Procesamiento del Lenguaje Natural (PLN) con grandes modelos de lenguaje (*Large Language Models*, LLMs).\n",
    "    - [`datasets`](https://huggingface.co/docs/datasets): Una librer칤a con funcionalidades para el tratamiento de los conjuntos de datos a utilizar para entrenar o ajustar los LLMs.\n",
    "    - [`tokenizers`](https://huggingface.co/docs/tokenizers): Una librer칤a para el proceso de \"tokenizaci칩n\", i.e. la divisi칩n de texto de manera discreta en palabras o subpalabras.\n",
    "- Hugging Face no s칩lo ofrece soluciones para PLN, sino tambi칠n para im치genes, con librer칤as como [`diffusers`](https://huggingface.co/docs/diffusers), para la generaci칩n de im치genes:\n",
    "    - Lectura recomendada: [The Illustrated Stable Diffusion](http://jalammar.github.io/illustrated-stable-diffusion/)\n",
    "\n",
    "Huggin Face es una empresa que busca desarrollar herramientas de c칩digo abierto para el dise침o, entrenamiento y puesta en producci칩n de modelos de inteligencia artificial. Creada en 2016, empez칩 a ganar popularidad gracias a su librer칤a transformers, la cual permite crear y entrenar redes neuronales con la arquitectura *Transformer* de manera sencilla e independiente del framework agn칩stica, pudiendo usar en el backend tanto Pytorch como Tensorflo o JAX. Hoy en d칤a, sin embargo, ofrece muchas otras funcionalidades tales como *Datasets*, Modelos pre-entrenados, herramientas para el entrenamiento y puesta en producci칩n de modelos a escala, etc. Recientemente incluso han inclu칤do en su cat치logo la librer칤a timm, para la generaci칩n de im치genes al estilo *DALL-E* o *Stable Diffusion*, indicando que Hugging Face est치 creciendo como comunidad, yendo m치s all치 de los *Transfromers* y sus aplicaciones en tareas de lenguaje hacia otros campos como el de la visi칩n artificial o el aprendizaje por refuerzo. \n",
    "\n",
    "## 쮺칩mo empezar con Hugging Face 游뱅?\n",
    "\n",
    "- Primero se [crea una cuenta en la p치gina](https://huggingface.co/join).\n",
    "- Luego podemos [crear modelos](https://huggingface.co/new) a trav칠s del men칰 que se despliega de nuestro avatar.\n",
    "\n",
    "Este es el esquema que seguiremos:\n",
    "\n",
    "**1.** Crear una cuenta de Hugging Face 游뱅\n",
    "* [crea una cuenta en la p치gina](https://huggingface.co/join).\n",
    "\n",
    "**2.** Crear un *Space* en Hugging Face y configurarlo\n",
    "* Los Spaces son repositorios Git que alojan c칩digo de aplicaci칩n para demos de Machine Learning.\n",
    "\n",
    "a- Seleccione el SDK de Space: **Gradio**.\n",
    "b- Space hardware: **Free**.\n",
    "c- Public.\n",
    "d- Create space.\n",
    "\n",
    "\n",
    "**Archivos necesarios:**  \n",
    "\n",
    "* .gitattributes (Creado automaticamente)\n",
    "* README.md (Creado automaticamente)\n",
    "* app.py (app propiamente dicha que realizara la predicci칩n)\n",
    "* model.pkl (modelo previamente entrenado)\n",
    "* requirements.txt (requirements del environment con el cual entrenamos nuestro modelo)\n",
    "\n",
    "\n",
    "**3.** Cargamos el modelo y el preprocesador previamente entrenados:\n",
    "\n",
    "* lin_reg.bin\n",
    "* preprocessor.b\n",
    "\n",
    "**4.** Crear y subir el archivo app.py que realizara el preprocesamiento y las predicciones:\n",
    "\n",
    "### **app.py** \n",
    "\n",
    "```bash\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import pathlib\n",
    "#plt = platform.system()\n",
    "#if plt == 'Linux': pathlib.WindowsPath = pathlib.PosixPath\n",
    "\n",
    "with open('lin_reg.bin', 'rb') as f_in:\n",
    "    (dv, model) = pickle.load(f_in)\n",
    "\n",
    "def prepare_features(ride):\n",
    "    features = {}\n",
    "    features['PU_DO'] = '%s_%s' % (ride['PULocationID'], ride['DOLocationID'])\n",
    "    features['trip_distance'] = ride['trip_distance']\n",
    "    return features\n",
    "    \n",
    "def predict(features):\n",
    "    X = dv.transform(features)\n",
    "    preds = model.predict(X)\n",
    "    return float(preds[0])\n",
    "\n",
    "def main(PULocationID,DOLocationID,trip_distance):\n",
    "    \"\"\"request input, preprocess it and make prediction\"\"\"\n",
    "    input_data = {\n",
    "    \"PULocationID\": PULocationID,\n",
    "    \"DOLocationID\": DOLocationID,\n",
    "    \"trip_distance\": trip_distance\n",
    "    }\n",
    "    features = prepare_features(input_data)\n",
    "    pred = predict(features)\n",
    "\n",
    "    result = {\n",
    "        'duration': pred\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "#create input and output objects\n",
    "#input\n",
    "input1 = gr.inputs.Number()\n",
    "input2 = gr.inputs.Number()\n",
    "input3 = gr.inputs.Number()\n",
    "\n",
    "#output object\n",
    "output = gr.outputs.Textbox() \n",
    "\n",
    "intf = gr.Interface(title = \"New York taxi duration prediction\",\n",
    "                    description = \"The objective of this project is to predict the duration of a taxi trip in the city of New York.\",\n",
    "                    fn=main, \n",
    "                    inputs=[input1,input2,input3], \n",
    "                    outputs=[output], \n",
    "                    live=True,\n",
    "                    enable_queue=True\n",
    "                    )\n",
    "intf.launch()\n",
    "```\n",
    "\n",
    "**5.** Crear y subir el archivo requirements.txt:\n",
    "\n",
    "### requirements.txt\n",
    "\n",
    "```bash\n",
    "pandas==2.1.1\n",
    "scikit-learn==1.3.1\n",
    "```\n",
    "\n",
    "**6.** Entrar a la ventana de App, esperar que se construya y realizar predicciones!!!.\n",
    "\n",
    "[Mi app](https://huggingface.co/spaces/martinnnuez/New_york_taxi_duration_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
